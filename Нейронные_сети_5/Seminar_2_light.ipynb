{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seminar_2_light.ipynb","private_outputs":true,"provenance":[{"file_id":"1E9h-s7tt1EsrHOZUiwUus3z2z23z8e_M","timestamp":1621404281506},{"file_id":"132Ky5Z8jUkNyqQXVnItgr89G5ztz0xlV","timestamp":1602561347482},{"file_id":"1_KjkkxptwxlvuJk-1-6TOFRkQx0UL8O4","timestamp":1577723176076},{"file_id":"1RNzGLTrWSDFSA5QyaXci5W1sBfGz6mnV","timestamp":1577723147474}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"sjAzhUMjuwvi"},"source":["# Семинар 2\n","\n","[Кишкун Анастасия](https://kichkun.github.io/)\n","[Аленичева Алиса](https://korney3.github.io/)"]},{"cell_type":"markdown","metadata":{"id":"Dh4Rh5SxeX94"},"source":["## 1) CIFAR10\n","\n","**CIFAR-10** - одна из стандартных задач классификации картинок.\n","\n","Датасет содержит $60000$ цветных фото объектов $10$ классов размером $32\\text{x}32$ пикселей.\n","\n","<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/3649/media/cifar-10.png\" width=\"500\">\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sB5rbMh2NIPe"},"source":["### Пререквизиты\n","Установим и загрузим необходимые библиотеки"]},{"cell_type":"code","metadata":{"id":"eACYHbFiNGVF"},"source":["!pip install numpy\n","!pip install pandas\n","!pip install tensorflow\n","!pip install keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6FdelQPNE4t"},"source":["%tensorflow_version 1.x\n","# Импортируем сам keras\n","import keras\n","# Последовательный тип модели\n","from keras.models import Sequential\n","# Импортируем полносвязный слой, слои активации и слой, \n","# превращающий картинку в вектор\n","from keras.layers import Dense, Activation, Flatten\n","# Импортируем сверточный слой, слои, фильтрующий максимальные значения из \n","# входных данных, слой \"выключающий часть нейронов\"\n","from keras.layers import Conv2D, MaxPooling2D, Dropout\n","\n","# Импортируем датасеты, чтобы вытащить оттуда нужные нам данные\n","import keras.datasets\n","\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","# Эти библиотеки отключают лишние предупреждения от библиотек, в частности,\n","# tensorflow, чтобы не засорять вывод наших результатов\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n","from tensorflow.python.util import deprecation\n","deprecation._PRINT_DEPRECATION_WARNINGS = False\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# keras является оболочкой для более низкоуровневых библиотек, \n","# в нашем случае мы используем tensorflow, у которого на данный момент \n","# поддерживаются две версии, установим первую\n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2yH6RlYrYx2U"},"source":["### Utils\n","\n","Здесь некоторые дополнительные функции, которые облегчат нам работу с данными.\n","\n","(В них разбираться не нужно, только запустить)"]},{"cell_type":"code","metadata":{"id":"q38ruusFnptL","cellView":"both"},"source":["def plot_dataset_samples_grid(image_data, dataset_name='', N=8):\n","  \"\"\"\n","    Эта функция строит NxN самплов из датасета image_data\n","\n","    Параметры\n","    ----------\n","    image_data : array\n","        Array of shape \n","        (number_of_samples, image_width, image_height, number of channels)\n","        with images\n","    dataset_name : str\n","        Name of dataset to write in the title\n","    N : int\n","        Size of grid of samples \n","  \"\"\"\n","  plt.figure(figsize=(10,10))\n","  data1=image_data[:N*N]\n","  \n","  image_width=image_data.shape[1]\n","  image_heigth=image_data.shape[2]\n","\n","  if len(data1.shape)==4:\n","    image_channels=image_data.shape[3]\n","    data1 = data1.reshape(N, N,image_width,image_heigth, image_channels)\n","    data1 = np.transpose(data1,(0,2,1,3,4))\n","    data1 = data1.reshape(N*image_width,N*image_heigth,image_channels)\n","    plt.imshow(data1)\n","\n","  elif len(data1.shape)==3:\n","    data1 = data1.reshape(N, N,image_width,image_heigth)\n","    data1 = np.transpose(data1,(0,2,1,3))\n","    data1 = data1.reshape(N*image_width,N*image_heigth)\n","    plt.imshow(data1,cmap='gray')\n","  plt.xticks([])\n","  plt.yticks([])\n","  plt.grid(False)\n","  plt.title('First '+ str(N*N) + ' '+dataset_name+ ' samples of training set')\n","  plt.show()\n","\n","def plot_CIFAR_samples(image_data, label_data, classes,  N=8):\n","  \"\"\"\n","    Эта функция строит N самплов каждого класса из датасета image_data\n","\n","    Параметры\n","    ----------\n","    image_data : array\n","        Array of shape \n","        (number_of_samples, image_width, image_height, number of channels)\n","        with images\n","    label_data : array\n","        Array of shape \n","        (number_of_samples, )\n","        with labels\n","    classes : dict\n","        Dictionary {class_number:class_name}\n","    dataset_name : str\n","        Name of dataset to write in the title\n","    N : int\n","        Number of samples for each class \n","  \"\"\"\n","  plt.figure(figsize=(10,N))\n","  num_classes = len(classes.keys())\n","  for i,key in enumerate(classes.keys()):\n","      idxs = np.flatnonzero(label_data == key)\n","      idxs = np.random.choice(idxs, N, replace=False)\n","      for i, idx in enumerate(idxs):\n","          plt_idx = i * num_classes + key + 1\n","          plt.subplot(N, num_classes, plt_idx)\n","          plt.imshow(image_data[idx].astype('uint8'))\n","          plt.axis('off')\n","          if i == 0:\n","              plt.title(classes[key])\n","  plt.show()\n","\n","from os import listdir, sep\n","from os.path import abspath, basename, isdir\n","def tree(dir, padding= '  ', print_files=False):\n","    \"\"\"\n","    Эта функция строит дерево поддиректорий и файлов для заданной директории\n","\n","    Параметры\n","    ----------\n","    dir : str\n","        Path to needed directory\n","    padding : str\n","        String that will be placed in print for separating files levels\n","    print_files : bool\n","        \"Print or not to print\" flag\n","    \"\"\"\n","    cmd = \"find '%s'\" % dir\n","    files = os.popen(cmd).read().strip().split('\\n')\n","    padding = '|  '\n","    for file in files:\n","        level = file.count(os.sep)\n","        pieces = file.split(os.sep)\n","        symbol = {0:'', 1:'/'}[isdir(file)]\n","        if not print_files and symbol != '/':\n","            continue\n","        print (padding*level + pieces[-1] + symbol)\n","\n","def plot_cats_dogs_samples(train_dir, N=4):\n","  \"\"\"\n","    Эта функция строит N самплов каждого класса из датасета Cats vs Dogs\n","\n","    Параметры\n","    ----------\n","    train_dir : str\n","        Directory with train Cats vs Dogs dataset\n","    N : int\n","        Number of samples for each class \n","  \"\"\"\n","  import random\n","  fig, ax = plt.subplots(2,N,figsize=(5*N,5*2))\n","\n","  for i,name in enumerate(['cat','dog']):\n","    filenames = os.listdir(os.path.join(train_dir,name))\n","    \n","    for j in range(N):\n","      sample = random.choice(filenames)\n","      image = load_img(os.path.join(train_dir,name,sample))\n","      ax[i][j].imshow(image)\n","      ax[i][j].set_xticks([])\n","      ax[i][j].set_yticks([])\n","      ax[i][j].set_title(name)\n","  plt.grid(False)\n","  plt.show()\n","\n","def load_special_images():\n","  \"\"\"\n","    Эта функция загружает 3 картинки для темы бинарной классификации кошек\n","    и собак\n","\n","    Returns\n","    ----------\n","    im1, im2, im3 : array\n","        Three images in a form of numpy array\n","  \"\"\"\n","  import requests\n","  from PIL import Image\n","  \n","  image_url_1 = 'https://preview.redd.it/4j8gx4ztzex01.png?width=960&crop=smart&auto=webp&s=5e80ab0071d56cc042f7b709648de8cde394832a'\n","  image_url_2 = 'https://cdn.images.express.co.uk/img/dynamic/128/590x/secondary/Viral-cat-sensation-715546.jpg'\n","  image_url_3 = 'https://www.sunnyskyz.com/uploads/2016/12/hmm9j-dog-or-cat-2.jpg'\n","\n","  im1 = Image.open(requests.get(image_url_1, stream=True).raw)\n","  im1 = np.array(im1)\n","  im2 = Image.open(requests.get(image_url_2, stream=True).raw)\n","  im2 = np.array(im2)\n","  im3 = Image.open(requests.get(image_url_3, stream=True).raw)\n","  im3 = np.array(im3)\n","\n","  return im1, im2, im3\n","\n","def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n","    \"\"\" \n","    Эта функция показывает 6 картинок с предсказанными и настоящими классами\n","    \"\"\"\n","    label_dict={0.:'cat',1.:'dog'}\n","    n = 0\n","    nrows = 5\n","    ncols = 5\n","    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True,figsize=(15,10))\n","    for row in range(nrows):\n","        for col in range(ncols):\n","            error = errors_index[n]\n","            ax[row,col].imshow((img_errors[error]).reshape((224,224,3)),cmap='gray')\n","            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(label_dict[pred_errors[error]],label_dict[obs_errors[error]]))\n","            n += 1\n","    plt.tight_layout()\n","\n","def image_to_batch(img, size=150):\n","  \"\"\" \n","    Эта функция переводит картинку размером (img_width,img_height, 3) в батч\n","    размером (1,size,size,3)\n","\n","    Parameters\n","    ----------\n","    img : array\n","        Image of size (img_width,img_height, 3)\n","    \n","    size : int\n","        Size of image in batch\n","    \n","    Returns\n","    ----------\n","    img_resized : array\n","        Batch of one image with shape (1,size,size,3)\n","  \"\"\"\n","  import cv2\n","  img_resized=cv2.resize(img,(size,size)).reshape(1,size,size,img.shape[2])\n","  return img_resized\n","\n","def plot_special_images(pred1,pred2,pred3):\n","  \"\"\"\n","    Эта функция строит 3 специальные картинки для датасета Cats vs Dogs\n","    с предсказаниями класса\n","\n","    Параметры\n","    ----------\n","    pred1,pred2,pred3  : arrays\n","        Arrays of shape one with probability of image to be of class 1\n","  \"\"\"\n","  im1, im2, im3 = load_special_images()\n","\n","  pred1 = np.asscalar(pred1)\n","  pred2 = np.asscalar(pred2)\n","  pred3 = np.asscalar(pred3)\n","\n","  preds=[pred1,pred2,pred3]\n","\n","  fig, ax = plt.subplots(1,3,figsize=(15,10))\n","\n","  ax[0].imshow(im1)\n","  ax[1].imshow(im2)\n","  ax[2].imshow(im3)\n","\n","  for i in range(3):\n","    ax[i].set_xticks([])\n","    ax[i].set_yticks([])\n","    if preds[i]>0.5:\n","      ax[i].set_title('Это собака с вероятностью\\n%.f проц.' % (preds[i]*100))\n","    else:\n","      ax[i].set_title('Это кошка с вероятностью\\n%.f проц.' % ((1-preds[i])*100))\n","\n","\n","  plt.grid(False)\n","  plt.show()\n","\n","def get_test_predictions(test_generator, model, dataset_len=2500):\n","  \"\"\"\n","    Эта функция вытаскивает из генератора все предсказания\n","\n","    Параметры\n","    ----------\n","    test_generator  : ImageDataGenerator\n","        Generator, producing batches (img, label)\n","    model : keras.model\n","        Model for getting predictions\n","    dataset_len : int\n","        Number of samples in generator\n","    \n","    Returns\n","    ----------\n","    preds_labels  : array\n","        Predicted labels\n","    preds_vec : array\n","        Predicted probabilities\n","    labels_vec : array\n","        True labels\n","    datas_vec : array\n","        Array of images\n","  \"\"\"\n","  labels=[]\n","  preds=[]\n","  datas=[]\n","\n","  samples=0\n","  for i,batch in enumerate(test_generator):\n","    data, label=batch\n","    labels.append(label)\n","    preds.append(model.predict(data))\n","    datas.append(data)\n","    samples+=len(data)\n","    if samples>=dataset_len:\n","      break\n","\n","  labels_vec=np.hstack(labels)\n","  preds_vec=np.hstack([pred.reshape(-1,) for pred in preds])\n","  datas_vec=np.vstack(datas)\n","  preds_labels=preds_vec.copy()\n","  preds_labels[preds_labels<0.5]=0\n","  preds_labels[preds_labels>=0.5]=1\n","\n","  return preds_labels, preds_vec, labels_vec, datas_vec"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UORI9pT29HvW"},"source":["### 1. Загрузка данных\n","Датасет уже лежит в библиотеке `keras`, загрузим его и посмотрим на содержание выборки."]},{"cell_type":"code","metadata":{"id":"EHWmbdGHn4l4"},"source":["# Импортируем модуль датасета CIFAR10\n","from keras.datasets import cifar10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HCVcwZBK7aJl"},"source":["# Выгрузим тренировочные и тестовые данные при помощи метода load_data\n","(X_train, y_train), (X_test, y_test) = cifar10.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvkKD70vYf7F"},"source":["# y_train и  y_test содержат классы картинок в виде чисел\n","# Соответствие между номером класса и его именем запишем в словарь,\n","# чтобы посмотреть, какие данные в каких классах у нас есть\n","LABEL_TRANSLATION={0: 'plane', 1: 'car', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tUIGHo6kahJf"},"source":["# Посмотрим на содержание датасета, вызвав функцию plot_CIFAR_samples,\n","# которая строит на одной картинке N самплов из массива картинок\n","# X_train для каждого класса\n","plot_CIFAR_samples(X_train, y_train, LABEL_TRANSLATION, N=7)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0bnBps50_FIi"},"source":["### 2. Подготовка данных \n","**Нормализация значений на [0,1] и перевод целевой переменной в one-hot формат**\n","\n","Аналогично задаче с датасетом **MNIST** нормализуем картинки (каждый пиксель представлен числом от $0$ до $255$) и переводим числа классов в **one-hot** вектора.\n","\n","**One-hot encoding** преобразование можно выполнить функцией\n"," `keras.utils.to_categorical`, которая на вход принимает вектор с целевой переменной и общее число классов."]},{"cell_type":"code","metadata":{"id":"L1XW7DwKsihv"},"source":["X_train = X_train / 255 \n","X_test = X_test / 255\n","\n","y_train = keras.utils.to_categorical(y_train, 10)\n","y_test = keras.utils.to_categorical(y_test, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xj2LQyFsAgE_"},"source":["### 3. Baseline\n","\n","\n","Построим сверточную нейросеть из двух **VGG**-блоков: последовательности слоев нейросети **conv-conv-maxpool**. \n","\n","**VGG** - семейство существующих архитектур нейросетей, которые демонстрируют одни из лучших результатов в задачах выделения признаков из картинок.\n","\n","Зададим функцию, создающую нейросеть - **define_model**."]},{"cell_type":"markdown","metadata":{"id":"g1v5yaHZY3xg"},"source":["Обратим внимание на новую опцию сверточных слоев  - **Kernel_initializer**. В ней мы можем выбрать способ определения начальных значений весов слоя.\n","\n","Чтобы нейросеть могла обучиться для решения определенной задачи, перед обучением нужно задать начальные значения весов, с которыми с одной стороны результат после прохождения входных данных по сети не будет стремиться к 0 или, наоборот, к бесконечно большому значению: в обоих случаях градиенты соответствующих весов будут либо исчезать (**vanishing**), то есть сеть не станет обучаться или, наоборот, скачкообразно увеличиваться (**exploding**), мешая весам сходиться к правильным значениям.\n","\n","Можно задавать веса случайными числами из нормального или равномерного распределений, не зависящих от конфигурации нейросети.\n","\n","В то же время [показано](https://https://arxiv.org/abs/1502.01852), что учитывание количества весов/размера слоев нейросети в параметрах случайных распределений позволяет лучше обучать нейросеть.\n","\n","Одним из таких специальный распределений является **he_uniform** - веса выбираются случайным образом из равномерного распределения внутри диапазона $[-limit, limit]$, где $limit = \\sqrt{\\frac{6}{fan_{in}}}$, $fan_{in}$ - размер ядра в случае со сверточными слоями."]},{"cell_type":"markdown","metadata":{"id":"RH4d5dr7ZnUk"},"source":["<table>\n","<tr>\n","<td>\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Uniform_Distribution_PDF_SVG.svg/1200px-Uniform_Distribution_PDF_SVG.svg.png\" width=\"500\">\n","</td>\n","<td>\n","<img src=\"https://wiki.analytica.com/images/4/4a/Normal%280%2C1%29.png\" width=\"500\">\n","</td>\n","</tr>\n","<tr>\n","<td>\n","Равномерное распределение\n","</td>\n","<td>\n","Нормальное распределение\n","</td>\n","</tr>\n","</table>"]},{"cell_type":"code","metadata":{"id":"yR977EcrpiOS"},"source":["def define_model():\n","  # Создаем пустую модель\n","  model = Sequential()\n","\n","#VGG1-блок\n","  # Начинаем со сверточных слоя, указывая тип активации на выходе из него,\n","  # способ заполнения краев (padding) и способ инициализации весов\n","  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n","  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","  # Здесь мы используем метод MaxPooling, который уменьшает размер обрабатываемого изображения, \n","  # выбирая из 4 пикселей 1 с максимальным значением, чтобы это быстрее считалось. (2,2) -> 1\n","  model.add(MaxPooling2D((2, 2)))\n","\n","  # Слой dropout, который на каждом шаге \"выключает\" 20% случайно выбранных нейронов\n","  model.add(Dropout(0.2))\n","\n","#VGG2-блок\n","  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","  model.add(MaxPooling2D((2, 2)))\n","  model.add(Dropout(0.2))\n","\n","  # Разворачиваем данные в вектор\n","  model.add(Flatten())\n","  # Добавляем полносвязные слои:\n","  # ReLU активация скрытого слоя\n","  model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n","  model.add(Dropout(0.2))\n","  # Знакомый нам softmax для выходного полносвязного слоя\n","  model.add(Dense(10, activation='softmax'))\n","\n","  # Компилируем модель с функцией ошибки categorical crossentropy, оптимизатором Адам \n","  # (оптимизатор, который со стандартным набором параметров может обучить эффективную\n","  # нейросеть), и метрикой - количеством правильно угаданных картинок.\n","  model.compile(loss='categorical_crossentropy',\n","                  optimizer = 'nadam',\n","                  metrics = ['accuracy'])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r81H7LCAGaoF"},"source":["# При помощи функции define_model строим последовательную сверточную нейросеть\n","base_model = define_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m1f6jJq_83gC"},"source":["base_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kArQ9gmsGdXi"},"source":["При помощи `fit` натренируем $30$ эпох нашу модель с размером батча $128$.\n","\n","На выходе мы получим натренированную модель и структуру данных типа словарь `history_cnn`, в котором в отдельных полях записана информация о ходе обучения модели"]},{"cell_type":"code","metadata":{"id":"vHx3x-yzBiyo"},"source":["history_cnn = base_model.fit(X_train, y_train,\n","              batch_size=128,\n","              epochs=30,\n","              validation_data=(X_test, y_test),\n","              shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rX0EFmNhwQVy"},"source":["def plot_history(history_cnn):\n","  plt.plot(history_cnn.history['val_accuracy'], '-o', label='validation accuracy')\n","  plt.plot(history_cnn.history['accuracy'], '--s', label='training accuracy')\n","  plt.xlabel('Количество эпох')\n","  plt.ylabel('Точность')\n","  plt.legend();"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wcbpMsxhGd-x"},"source":["# Построим графики точности на валидационной (val_acc) и трейновой (acc) выборках\n","# в конце каждой эпохи обучения\n","plot_history(history_cnn)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ETyWNNw2i6WO"},"source":["Точность на валидационной выборке (синяя линия) быстро сбавляет скорость роста и уступает точности на тренировочном датасете (оранжевая линия), так что мы немного переобучаемся, несмотря на слои **Dropout**."]},{"cell_type":"markdown","metadata":{"id":"3DHMY_C1Y490"},"source":["\n","Посмотрим на результаты классификации."]},{"cell_type":"code","metadata":{"id":"g3c-ItEMTpo6"},"source":["# Выведем метрики качества нашей нейросети (функцию ошибки и точность)\n","# для тестовой выборки\n","\n","base_model.evaluate(X_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mLkZ6gGDn35L"},"source":["## 2) Переобучение. Аугментация данных\n","\n","Еще один способ решения проблемы переобучения сети - аугментация (\"дополнение\") тренировочного датасета без привлечения реальных новых картинок.\n"," \n","Попробуем изменять наши исходные картинки перед тем, как они попадут в сетку при помощи различных трансформаций.\n","\n","Конечно, можно было бы поштучно изменить каждую картинку, сохранить, как новый датасет и тренировать модель уже на нем.\n","\n","Но это дает меньшую вариативность преобразований, занимает много места и памяти. Чтобы не изменять каждую картинку вручную, используют генераторы.\n","\n","Создадим такой генератор на основе наших данных при помощи модуля из `keras` библиотеки `ImageDataGenerator`."]},{"cell_type":"markdown","metadata":{"id":"GRhZ0BSoa4GW"},"source":["### 4. Генератор батчей с трансформацией"]},{"cell_type":"code","metadata":{"id":"HByjbEtCn_vV"},"source":["# Импортируем нужный нам модель генератора\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gt316leKkeYz"},"source":["Создадим модуль ImageDataGenerator.\n","\n","В качестве параметров укажем, какие изменения для картинок будем использовать.\n","\n","В данном случае:\n","\n","**width_shift_range**=0.1 - случайный сдвиг изображение по горизонтали на 0.1 ширины;\n","\n","**height_shift_range**=0.1 - случайный сдвиг изображение по вертикали на 0.1 высоты;\n","\n","**horizontal_flip**=True - случайно отражает картинку по горизонтали"]},{"cell_type":"markdown","metadata":{"id":"0XPAr7TiMPO2"},"source":["Таким образом, мы увеличиваем наш датасет, давая нейросети большую вариативность входных данных."]},{"cell_type":"code","metadata":{"id":"OW8qxKUAK_zF"},"source":["datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CixaBO4MGmeP"},"source":["Применим полученные трансформации к нашим исходным данным.\n","\n","\n","Обратите внимание, что размер батча **batch_size** нужно указать здесь, чтобы генератор знал, \n","сколько картинок ему выдавать модели при обучении.\n","\n","Теперь при обращении к `train_generator` мы сможем получать измененные изображения.\n","\n","При помощи метода `flow` получим генератор, связанный с нашими данными"]},{"cell_type":"code","metadata":{"id":"KSbp_soUMaD0"},"source":["train_generator = datagen.flow(X_train, y_train, batch_size=128)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h6rIj5_QG12Q"},"source":["`train_generator` является итератором, т.е., чтобы получить батч элементов\n","нужно выполнить какую-то итерирующую функцию: например, цикл `for`."]},{"cell_type":"code","metadata":{"id":"nAkrGW8yGzwk"},"source":["for img in train_generator:\n","  img=img[0]\n","  break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CCDMaVj-VblT"},"source":["# Построим 8х8 трансформированных элементов нашего датасета\n","# при помощи функции plot_dataset_samples_grid\n","\n","plot_dataset_samples_grid(img, dataset_name='transformed CIFAR10', N=8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTU8Pk6atVpB"},"source":["Вызовем функцию define_model, объявленную выше, которая создает модель нейросети из двух **VGG** блоков"]},{"cell_type":"code","metadata":{"id":"eAc1KML0p8Uf"},"source":["# Определим новую модель\n","gen_model = define_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xGSnJ_4INfK9"},"source":["#  Обучим модель с данными из генератора при помощи .fit_generator,\n"," \n","# На выходе все так же мы получим натренированную модель и структуру history_cnn, \n","# из которой можно достать значения функции ошибки и метрик качества на обеих выборках\n","history_cnn = gen_model.fit_generator(train_generator,\n","                        epochs=30,\n","                        validation_data=(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqgpynwoR6Ma"},"source":["# Посмотрим на изменение точности на валидационной (val_acc) и трейновой (acc) выборках\n","# с каждой эпохой\n","plot_history(history_cnn)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0LXoc5SnqfeU"},"source":["\n","Видно, что точность на валидационной выборке еще не вышла на \"плато\", а модель не успела переобучиться, значит, при увеличении числа эпох тренировки мы сможем еще увеличить нашу точность на валидационном наборе данных.\n","\n","Ай да аугментация!"]},{"cell_type":"code","metadata":{"id":"5cbgFcDRTbTc"},"source":["gen_model.evaluate(X_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3yQb1lx3wr6R"},"source":["### Вывод\n","\n","Аугментация тренировочной выборки положительно влияет на обобщающую способность сети, позволяя нейросети улавливать свойства целого класса, а не небольшой выборки тренировочных данных."]},{"cell_type":"markdown","metadata":{"id":"yRJZlhiO4y8l"},"source":["## 4) Cats vs Dogs\n","\n","\n","\n","Теперь мы поработаем с датасетом, который не входит в набор стандартных датасетов библиотеки Keras, поэтому данные придется загружать из внешнего источника.\n","\n","Загрузим датасет для бинарной классификации кошек и собак. Попробуем заставить нашу сеть ответить на вопрос: это кошки или собаки?\n","\n","\n","\n","\n","<table>\n","<tr>\n","<td>\n","<img src=\"https://preview.redd.it/4j8gx4ztzex01.png?width=960&crop=smart&auto=webp&s=5e80ab0071d56cc042f7b709648de8cde394832a\" width=\"200\">\n","</td>\n","<td>\n","</td>\n","</tr>\n","<tr>\n","<td>\n","<img src=\"https://cdn.images.express.co.uk/img/dynamic/128/590x/secondary/Viral-cat-sensation-715546.jpg\" width=\"200\">\n","</td>\n","<td>\n","<img src=\"https://www.sunnyskyz.com/uploads/2016/12/hmm9j-dog-or-cat-2.jpg\" width=\"200\">\n","</td>\n","</tr>\n","</table>\n","\n"]},{"cell_type":"code","metadata":{"id":"1HEm7hWqheZn"},"source":["# Импортируем функцию для загрузки картинок из файлов и генератор картинок\n","from keras.preprocessing.image import load_img, ImageDataGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KV8WbtlelQ69"},"source":["#### 1. Загрузка данных"]},{"cell_type":"code","metadata":{"id":"N500M6jbYjWr"},"source":["!wget -c https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip\n","!unzip -qq Cat_Dog_data.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ufx_rs3HmGKv"},"source":["Теперь наши данные хранятся в папке `Cat_Dog_data` с разделением на поддиректории `train` и `test`.\n","\n","Элементы каждого класса хранятся в своей директории (`cat` или `dog`). "]},{"cell_type":"code","metadata":{"id":"nzedwM1kdLGu"},"source":["base_dir = 'Cat_Dog_data'\n","\n","train_dir = os.path.join(base_dir, 'train')\n","\n","test_dir = os.path.join(base_dir, 'test')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ieOgnayTlktP"},"source":["# Посмотрим, как именно расположены директории с датасетом относительно друг друга\n","tree(base_dir,print_files=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y516C_dGoVjn"},"source":["#Посмотрим на содержание датасета при помощи функции plot_cats_dogs_samples\n","plot_cats_dogs_samples(train_dir, N=4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pZUeVRDVndHv"},"source":["### 2. Подготовка данных \n","\n","\n","Такой формат хранения удобен для использования функции генератора изображений `flow_from_directory`. \n","\n","Генератор не будет выкачивать все данные в оперативную память, а будет поочередно считывать из директорий нужные изображения и складывать их в батчи."]},{"cell_type":"markdown","metadata":{"id":"0P7jRpfi9wIN"},"source":["Создадим `ImageDataGenerator` для трейновой и тестовой выборок, поскольку обе выборки нужно доставать из директорий.\n","\n","Укажем преобразование, нормализующее изображения "]},{"cell_type":"code","metadata":{"id":"tywc4Vgff9K-"},"source":["train_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0TOc_ySJ96NA"},"source":["Зададим поток тренировочных батчей из директории **train** и **test**;\n","\n","Приведем все изображения к одному квадратному формату;\n","\n","Укажем, что работаем с задачей бинарной классификации"]},{"cell_type":"code","metadata":{"id":"v5EzzBC0bMEv"},"source":["#Теперь для создания генератора вместо метода flow мы польщуемся \n","# flow_from_directory\n","\n","train_generator = train_datagen.flow_from_directory(\n","        train_dir,  # Путь к директории с трейновой выборкой\n","        target_size=(150, 150),  # Размер изображений, к которому нужно привести все данные\n","        batch_size=128,\n","        #Генератор автоматически расставит бинарные лейблы для классов cat и dog\n","        class_mode='binary')\n","\n","\n","test_generator = test_datagen.flow_from_directory(\n","        test_dir,\n","        target_size=(150, 150),\n","        batch_size=128,\n","        class_mode='binary')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1LJg_MOywdJB"},"source":["# Соотношение между номером класса и его названием запишем в словарь\n","LABEL_DICT={1:'dog',0:'cat'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h0MHN6ccdDsz"},"source":["# train_generator является итератором, т.е., чтобы получить батч элементов\n","# нужно выполнить какую-то итерирующую функцию: например, цикл for\n","for img in train_generator:\n","  img=img[0]\n","  break\n","\n","#Посмотрим, какие у нас вышли картинки при помощи функции plot_dataset_samples_grid\n","plot_dataset_samples_grid(img,'Cats vs Dogs', N=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xd0B9YHxtQkY"},"source":["### 3. Baseline\n","Для сравнения построим небольшую  baseline сверточную модель, состоящую из трех блоков **conv-maxpool** и пары полносвязных слоев.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"E5qCBdR71eQ2"},"source":["Размер входящего изображения `input_shape`=($150$, $150$, $3$), активация последнего слоя - `sigmoid` вместо `softmax`, поскольку мы работаем со случаем бинарной классификации. На выходе мы получим вероятность от $0$ до $1$, что картинка принадлежит к классу $1$ (**dog**).\n"]},{"cell_type":"code","metadata":{"id":"CGBbKr7tuB-I"},"source":["def define_model():\n","  # Создаем пустую модель\n","  model = Sequential()\n","\n","#1й сверточный блок\n","  # Начинаем со сверточных слоя, указывая тип активации ReLU\n","  model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n","  # Здесь мы используем метод MaxPooling, который уменьшает размер обрабатываемого изображения, \n","  # выбирая из 4 пикселей 1 с максимальным значением, чтобы это быстрее считалось. (2,2) -> 1\n","  model.add(MaxPooling2D((2, 2)))\n","\n","#2й сверточный блок\n","  model.add(Conv2D(32, (3, 3), activation='relu'))\n","  model.add(MaxPooling2D((2, 2)))\n","\n","#3й сверточный блок\n","  model.add(Conv2D(64, (3, 3), activation='relu'))\n","  model.add(MaxPooling2D((2, 2)))\n","\n","  # Разворачиваем данные в вектор\n","  model.add(Flatten())\n","  # Добавляем полносвязные слои:\n","  # ReLU активация скрытого слоя\n","  model.add(Dense(512, activation='relu'))\n","  # Sigmoid в качестве активации и одна выходная переменная - \n","  # вероятность, что картинка принадлежит к классу 1\n","  model.add(Dense(1, activation='sigmoid'))\n","\n","\n","  # Компилируем модель с функцией ошибки binary crossentropy, оптимизатором Адам \n","  # (оптимизатор, который со стандартным набором параметров может обучить эффективную\n","  # нейросеть), и метрикой - количеством правильно угаданных картинок.\n","  model.compile(loss='binary_crossentropy',\n","                  optimizer = 'adam',\n","                  metrics = ['accuracy'])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JUq8itUCtcWQ"},"source":["# Создаем новую модель\n","base_model = define_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mj4A1wkSu4xj"},"source":["#Посмотрим, из чего наша модель состоит\n","base_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wUDR0_SeQRoB"},"source":["history = base_model.fit_generator(\n","      train_generator,\n","      epochs=7,\n","      validation_data=test_generator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQFy_Gp3SUBH"},"source":["# Построим изменение точности на трейновой (оранжевая линия) и тестовой (синяя линия) \n","# выборках\n","plt.plot(history.history['val_accuracy'], '-o', label='validation accuracy')\n","plt.plot(history.history['accuracy'], '--s', label='training accuracy')\n","plt.legend();"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sa_ArfcFDFOe"},"source":["# Взглянем на итоговые результаты классификации на тестовой выборке \n","# (функция ошибки, точность)\n","base_model.evaluate(test_generator)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h3Ux6JuYTeeU"},"source":["Видно, что точность на тестовой выборке практически сразу вышла на плато около $0.8$, а точность на трейновой выборке почти достигла $1$, поэтому с такой моделью улучшить точность на новых данных уже вряд ли выйдет. \n","\n","Будем пробовать улучшать показатели радикальными способами, но сначала посмотрим, что эта сеть думает по поводу зоопарка из описания датасета."]},{"cell_type":"markdown","metadata":{"id":"Bx5OzssrDFOj"},"source":["### 4. Evaluation на особенных картинках\n","\n","Посмотрим, что скажет нейросеть по поводу наших особенных картинок"]},{"cell_type":"code","metadata":{"id":"9djkrTxTDFOv"},"source":["# Загрузим картинки из описания задачи при помощи функции load_special_images()\n","im1, im2, im3 = load_special_images()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1eo1Uxp0OK4b"},"source":["Изменим размер картинок на размер входных данных нейросети ($150$х$150$).\n","\n","Добавим дополнительную размерность, поскольку сеть принимает картинки с еще одной размерностью батча. \n","\n","Все это делаем при помощи функции `image_to_batch`"]},{"cell_type":"code","metadata":{"id":"rdzYydbVNAy7"},"source":["im1_150 = image_to_batch(im1, 150)\n","im2_150 = image_to_batch(im2, 150)\n","im3_150 = image_to_batch(im3, 150)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GkecH5JVUwIZ"},"source":["im1_150.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MdMmyxXLVOPY"},"source":["im1_150.max()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p3MLiDjEU8M9"},"source":["Заметим, что прежде, чем подавать картинки в нейросеть их нужно не забыть **отнормировать**!"]},{"cell_type":"code","metadata":{"id":"SHdK7DQSVceI"},"source":["im1_150 = im1_150/255.\n","im2_150 = im2_150/255.\n","im3_150 = im3_150/255."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q_OQcIIFVyDa"},"source":["Получим вероятности, что на картинках собаки, используя метод `predict`\n","нашей модели `base_model`"]},{"cell_type":"code","metadata":{"id":"-yTPAv6aV3lQ"},"source":["pred1 = base_model.predict(im1_150)\n","pred2 = base_model.predict(im2_150)\n","pred3 = base_model.predict(im3_150)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yJG9NENkV-Db"},"source":["pred3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KL0oHP6ucRMp"},"source":["Посмотрим, для какой картинки какое предсказание дала нейросеть\n","при помощи функции `plot_special_images`"]},{"cell_type":"code","metadata":{"id":"JYLbAwPgWTfE"},"source":["plot_special_images(pred1,pred2,pred3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bzo7Xp0ukQ7M"},"source":["## 5. Transfer learning\n","\n","Использование предобученных моделей для новых задач"]},{"cell_type":"markdown","metadata":{"id":"aPkCA-znkVUA"},"source":["Как уже упоминалось ранее, есть архитектуры нейросетей, которые зарекомендовали себя в решении определенного класса задач, как, например, **VGG16**.\n","\n","<img src=\"https://www.researchgate.net/profile/Max_Ferguson/publication/322512435/figure/download/fig3/AS:697390994567179@1543282378794/Fig-A1-The-standard-VGG-16-network-architecture-as-proposed-in-32-Note-that-only.png\" width=\"700\">\n","\n","\n","**VGG16** и подобные ей модели содержат большое количество параметров и обучение их с нуля может занять большое количество времени. \n","\n","Кроме того, бывают задачи, где данных изначально небольшое количество и даже аугментация не сильно спасает положение, тогда обучение сверточной сети может не быть очень успешным.\n","\n","Поэтому можно использовать модель, которая уже была кем-то предобучена, загрузить ее веса и дообучать только последние слои, подстраивая их под свою конкретную задачу! "]},{"cell_type":"markdown","metadata":{"id":"xSaWd-k_ymHe"},"source":["#### План работы:\n","\n","1.   Загрузить предобученную VGG16 модель без последних полносвязных слоев, отвечающих за конкретную задачу\n","2.   Построить свою полносвязную сеть для бинарной классификации кошек и собак\n","3.   Соединить две модели в одну!\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_2Xnlx0CHikE"},"source":["### 1) Подготовим данные"]},{"cell_type":"markdown","metadata":{"id":"SM3r_OjaCFJe"},"source":["Создадим `ImageDataGenerator` для трейновой и тестовой выборок,\n","указав преобразование, нормализующее изображения"]},{"cell_type":"code","metadata":{"id":"1cmGKctC76pZ"},"source":["train_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IaclpE8sCKtB"},"source":["Изменим размеры картинок dataloader, поскольку модель **VGG16** принимает входные значения стандартизированного размера $224$х$224$x$3$.\n","\n","Зададим поток тренировочных батчей из директории **train** и **test**.\n","\n","Приведем все изображения к одному квадратному формату.\n","\n","Укажем, что работаем с задачей бинарной классификации."]},{"cell_type":"code","metadata":{"id":"5_60pKkpCLZ-"},"source":["train_generator = train_datagen.flow_from_directory(\n","        train_dir,  # Путь к директории с трейновой выборкой\n","        target_size=(224, 224),  # Размер изображений, к которому нужно привести все данные\n","        batch_size=128,\n","        #Генератор автоматически расставит бинарные лейблы для классов cat и dog\n","        class_mode='binary')\n","\n","\n","test_generator = test_datagen.flow_from_directory(\n","        test_dir,\n","        target_size=(224, 224),\n","        batch_size=128,\n","        class_mode='binary')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i6SrSE0ryrwF"},"source":["### 2) Загрузим VGG16"]},{"cell_type":"markdown","metadata":{"id":"Wf8mGH-OChhs"},"source":["В библиотеке `Keras` уже представлены архитектуры **State-of-the-art** моделей, поэтому можно достать **VGG16** модель одной строчкой кода."]},{"cell_type":"code","metadata":{"id":"Gr8hID-MiIH7"},"source":["from keras.applications import vgg16 as vgg"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a-OGonqoCr13"},"source":["Создадим **VGG** модель, в качестве параметра `weights` укажем `imagenet` - название\n","большого датасета с картинками, на котором сеть была натренирована;\n","\n","`include_top` - False - не включать полносвязные слои вверху нейросети"]},{"cell_type":"code","metadata":{"id":"VMX3wv9giIIE"},"source":["vgg_model = vgg.VGG16(weights='imagenet', \n","                       include_top=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rEQ_vQqBiIIH"},"source":["#Посмотрим, из чего состоит VGG модель\n","vgg_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BXDjuyQoC9xS"},"source":["Достанем последний слой `block5_pool` из **VGG** модели.\n","\n","Сверху него мы далее построим наш классификатор."]},{"cell_type":"code","metadata":{"id":"iaQtK_YeiIIM"},"source":["last = vgg_model.get_layer('block5_pool').output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"feJBBfp8HtR1"},"source":["### 3) Добавим небольшую нейросеть для бинарной классификации"]},{"cell_type":"code","metadata":{"id":"JQ-m8LXjiIIU"},"source":["# Модуль, с помощью которого мы будем \"сшивать\" последовательные модели\n","from keras.engine import Model\n","# Импортируем Pooling по всему слою входных данных и нормализацию батчей\n","from keras.layers import GlobalAveragePooling2D, BatchNormalization"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3v7sHFlPD1oa"},"source":["Добавим сверху слоя `last` **VGG** модели свои слои для классификации"]},{"cell_type":"code","metadata":{"id":"3OAU8Hh5D0vy"},"source":["# Добавим новые GAP (вместо FLatten) и BatchNormalization слои\n","x = GlobalAveragePooling2D()(last)\n","x = BatchNormalization()(x)\n","\n","# Привычные полносвязные слои\n","x = Dense(512, activation='relu')(x)\n","x = Dense(256, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","pred = Dense(1, activation='sigmoid')(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-HgG66mdEDRu"},"source":["Объединим **VGG16** и **классификатор** в одного трансформера при помощи модуля `Model`"]},{"cell_type":"code","metadata":{"id":"CGfvGA-HiIIY"},"source":["fin_model = Model(vgg_model.input, pred)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4CZkOgPkEKly"},"source":["Теперь самое важное: нам не нужно изменять и так хорошо натренированные веса\n","исходной модели, поэтому мы **\"замораживаем\"** их, при тренировке они будут использоваться\n","только для вычисления выходных данных"]},{"cell_type":"code","metadata":{"id":"rKubJK6ciIIe"},"source":["for layer in vgg_model.layers:\n","     layer.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zeGc053ZiIIi"},"source":["# Скомпилируем модель с функцией ошибки binary crossentropy, оптимизатором Адам \n","# (оптимизатор, который со стандартным набором параметров может обучить эффективную\n","# нейросеть), и метрикой - количеством правильно угаданных картинок.\n","fin_model.compile(loss='binary_crossentropy',\n","                  optimizer = 'adam',\n","                  metrics = ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jB3q9jH7iIIn"},"source":["fin_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WdAJqfZCeOOr"},"source":["# Поставим модель обучаться 5 эпох при помощи модуля fit_generator\n","history_cnn = fin_model.fit_generator(train_generator,\n","              epochs=5,\n","              validation_data=test_generator,\n","              shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1M7KqPCQiIIv"},"source":["plt.plot(history_cnn.history['val_accuracy'], '-o', label='validation accuracy')\n","plt.plot(history_cnn.history['accuracy'], '--s', label='training accuracy')\n","plt.legend();"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oymCEXpwiIIz"},"source":["fin_model.evaluate(test_generator)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fGAqTREkac91"},"source":["Использование предобученной модели **VGG** уже с 1й эпохи позволило нейросети достичь точности $>90$% на тестовой выборке!\n","\n","Хотя и здесь изменение точности вышло на плато, текущий результат сильно превосходит бейзлайн и позволяет на его основе строить еще более мощные предсказательные модели."]},{"cell_type":"markdown","metadata":{"id":"pTNb1JngPzic"},"source":["### 4) Посмотрим результаты на особенных картинках"]},{"cell_type":"markdown","metadata":{"id":"rIgypbDyEcgT"},"source":["Изменим размер как у входных данных сети ($224х224$) и добавим дополнительную размерность при помощи функции `image_to_batch`"]},{"cell_type":"code","metadata":{"id":"NXrqTtZoLzCB"},"source":["im1_224=image_to_batch(im1,224)\n","im2_224=image_to_batch(im2,224)\n","im3_224=image_to_batch(im3,224)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wh2Q2C5Mbe2N"},"source":["Не забудем про нормировку!"]},{"cell_type":"code","metadata":{"id":"FvnfSBX0bWAi"},"source":["im1_224 = im1_224/255.\n","im2_224 = im2_224/255.\n","im3_224 = im2_224/255."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iorVgg2xEld6"},"source":["Получим вероятности, что на картинках собаки (используйте метод `predict`)\n"]},{"cell_type":"code","metadata":{"id":"gnzUtdaZbSjj"},"source":["pred1 = fin_model.predict(im1_224)\n","pred2 = fin_model.predict(im2_224)\n","pred3 = fin_model.predict(im3_224)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ml08-Fr9byna"},"source":["Посмотрим, для какой картинки какое предсказание дала нейросеть при помощи функции `plot_special_images`"]},{"cell_type":"code","metadata":{"id":"Pa-gFdjebx2U"},"source":["plot_special_images(pred1,pred2,pred3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zLWocMGUb9HM"},"source":["Как видно, несмотря на то, что нейросеть в целом хорошо \"понимает\" устройство основной выборки кошек и собак, особые случаи ей ясны уже не так хорошо. Хотя модель поняла, что в центре кошка, собаку с кошачьими глазами она перепутала с котом."]},{"cell_type":"markdown","metadata":{"id":"ndqpsNVQx_7a"},"source":["## Выводы\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"X9eq7WKr1_My"},"source":["\n","1.   Мы обучили сверточную нейросеть на датасете из цветных фото из $10$ классов - **CIFAR10**\n","\n","2.   Познакомились с различными видами трансформаций картинок, которые можно применять к своим данным при помощи генератора батчей - **`ImageDataGenerator()`**\n","\n","3. Использовали **аугментированные** генератором данные для преодоления переобучения модели\n","\n","4.  Научились работать не только с встроенными датасетами `keras`, но и загрузили новый датасет для **бинарной** классификации **Cats vs Dogs**\n","\n","5.  Познакомились со **state-of-the-art** моделью для вытаскивания признаков из картинок - **VGG16**\n","6. Узнали, что такое **transfer learning**, использовали предобученную **VGG16** модель для создания своего классификатора, достигли точности $>90$% на тестовой выборке с $1$й эпохи\n","\n"," \\+ Бонус для самых любопытных - **сегментация**"]},{"cell_type":"markdown","metadata":{"id":"WVKVnl_Q4w1R"},"source":["## [Бонусный нотебук](https://colab.research.google.com/drive/1XFJirVAEDPp7ful4Amn5EHqP7pRHo8Ff)"]}]}