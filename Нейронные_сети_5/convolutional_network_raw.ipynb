{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.13"},"colab":{"name":"convolutional_network_raw.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"collapsed":true,"id":"OdcSBafAZjtV"},"source":["# Convolutional Neural Network Example\n","\n","Build a convolutional neural network with TensorFlow.\n","\n","- Author: Aymeric Damien\n","- Project: https://github.com/aymericdamien/TensorFlow-Examples/"]},{"cell_type":"markdown","metadata":{"id":"dyJKRGKLZjte"},"source":["## CNN Overview\n","\n","![CNN](http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png)\n","\n","## MNIST Dataset Overview\n","\n","This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. For simplicity, each image has been flattened and converted to a 1-D numpy array of 784 features (28*28).\n","\n","![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n","\n","More info: http://yann.lecun.com/exdb/mnist/"]},{"cell_type":"code","metadata":{"id":"UVqJfShfZjti","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621496502294,"user_tz":-180,"elapsed":1546,"user":{"displayName":"Дмитрий Гатилов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0DTJTuPknlwRuD9nvY-91EHrX-nFPt5urreT9wQ=s64","userId":"11957985684084033881"}},"outputId":"2f8d26ef-ede6-4ecf-f0de-d2cd90530b35"},"source":["from __future__ import division, print_function, absolute_import\n","\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# Import MNIST data\n","\n","mnist = keras.datasets.mnist.load_data()\n","#from tensorflow.examples.tutorials.mnist import input_data\n","#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"lz5PsagSZjtr","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"error","timestamp":1621496530355,"user_tz":-180,"elapsed":908,"user":{"displayName":"Дмитрий Гатилов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0DTJTuPknlwRuD9nvY-91EHrX-nFPt5urreT9wQ=s64","userId":"11957985684084033881"}},"outputId":"28b75f5d-2252-4d12-9e7f-7cf21853020d"},"source":["# Training Parameters\n","learning_rate = 0.001\n","num_steps = 500\n","batch_size = 128\n","display_step = 10\n","\n","# Network Parameters\n","num_input = 784 # MNIST data input (img shape: 28*28)\n","num_classes = 10 # MNIST total classes (0-9 digits)\n","dropout = 0.75 # Dropout, probability to keep units\n","\n","# tf Graph input\n","X = tf.placeholder(tf.float32, [None, num_input])\n","Y = tf.placeholder(tf.float32, [None, num_classes])\n","keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)"],"execution_count":4,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-4-b5fd7c5375c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# tf Graph input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dropout (keep probability)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'placeholder'"]}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"9lVovG0hZjtt","executionInfo":{"status":"ok","timestamp":1621496530361,"user_tz":-180,"elapsed":908,"user":{"displayName":"Дмитрий Гатилов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0DTJTuPknlwRuD9nvY-91EHrX-nFPt5urreT9wQ=s64","userId":"11957985684084033881"}}},"source":["# Create some wrappers for simplicity\n","def conv2d(x, W, b, strides=1):\n","    # Conv2D wrapper, with bias and relu activation\n","    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n","    x = tf.nn.bias_add(x, b)\n","    return tf.nn.relu(x)\n","\n","\n","def maxpool2d(x, k=2):\n","    # MaxPool2D wrapper\n","    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n","                          padding='SAME')\n","\n","\n","# Create model\n","def conv_net(x, weights, biases, dropout):\n","    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n","    # Reshape to match picture format [Height x Width x Channel]\n","    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n","    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n","\n","    # Convolution Layer\n","    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n","    # Max Pooling (down-sampling)\n","    conv1 = maxpool2d(conv1, k=2)\n","\n","    # Convolution Layer\n","    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n","    # Max Pooling (down-sampling)\n","    conv2 = maxpool2d(conv2, k=2)\n","\n","    # Fully connected layer\n","    # Reshape conv2 output to fit fully connected layer input\n","    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n","    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n","    fc1 = tf.nn.relu(fc1)\n","    # Apply Dropout\n","    fc1 = tf.nn.dropout(fc1, dropout)\n","\n","    # Output, class prediction\n","    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n","    return out"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"VwbBiVjKZjtw","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"error","timestamp":1621496530848,"user_tz":-180,"elapsed":1391,"user":{"displayName":"Дмитрий Гатилов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0DTJTuPknlwRuD9nvY-91EHrX-nFPt5urreT9wQ=s64","userId":"11957985684084033881"}},"outputId":"a318d280-6163-4c55-9d60-339cf9819e90"},"source":["# Store layers weight & bias\n","weights = {\n","    # 5x5 conv, 1 input, 32 outputs\n","    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n","    # 5x5 conv, 32 inputs, 64 outputs\n","    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n","    # fully connected, 7*7*64 inputs, 1024 outputs\n","    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n","    # 1024 inputs, 10 outputs (class prediction)\n","    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n","}\n","\n","biases = {\n","    'bc1': tf.Variable(tf.random_normal([32])),\n","    'bc2': tf.Variable(tf.random_normal([64])),\n","    'bd1': tf.Variable(tf.random_normal([1024])),\n","    'out': tf.Variable(tf.random_normal([num_classes]))\n","}\n","\n","# Construct model\n","logits = conv_net(X, weights, biases, keep_prob)\n","prediction = tf.nn.softmax(logits)\n","\n","# Define loss and optimizer\n","loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n","    logits=logits, labels=Y))\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","train_op = optimizer.minimize(loss_op)\n","\n","\n","# Evaluate model\n","correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","\n","# Initialize the variables (i.e. assign their default value)\n","init = tf.global_variables_initializer()"],"execution_count":6,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-6-3814cdbf73dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m weights = {\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# 5x5 conv, 1 input, 32 outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m'wc1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 5x5 conv, 32 inputs, 64 outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m'wc2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'random_normal'"]}]},{"cell_type":"code","metadata":{"id":"BhP0Lb0PZjty","executionInfo":{"status":"aborted","timestamp":1621496530844,"user_tz":-180,"elapsed":1378,"user":{"displayName":"Дмитрий Гатилов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0DTJTuPknlwRuD9nvY-91EHrX-nFPt5urreT9wQ=s64","userId":"11957985684084033881"}}},"source":["# Start training\n","with tf.Session() as sess:\n","\n","    # Run the initializer\n","    sess.run(init)\n","\n","    for step in range(1, num_steps+1):\n","        batch_x, batch_y = mnist.train.next_batch(batch_size)\n","        # Run optimization op (backprop)\n","        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n","        if step % display_step == 0 or step == 1:\n","            # Calculate batch loss and accuracy\n","            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n","                                                                 Y: batch_y,\n","                                                                 keep_prob: 1.0})\n","            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n","                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n","                  \"{:.3f}\".format(acc))\n","\n","    print(\"Optimization Finished!\")\n","\n","    # Calculate accuracy for 256 MNIST test images\n","    print(\"Testing Accuracy:\", \\\n","        sess.run(accuracy, feed_dict={X: mnist.test.images[:256],\n","                                      Y: mnist.test.labels[:256],\n","                                      keep_prob: 1.0}))\n"],"execution_count":null,"outputs":[]}]}